,vocab_size,max_position_embeddings,hidden_size,logit_scale,intermediate_size,num_hidden_layers,num_attention_heads,num_key_value_heads,hidden_act,initializer_range,layer_norm_eps,use_cache,rope_theta,rope_scaling,attention_bias,attention_dropout,sliding_window,sliding_window_pattern,head_dim,cache_implementation,return_dict,output_hidden_states,output_attentions,torchscript,torch_dtype,use_bfloat16,tf_legacy_loss,pruned_heads,tie_word_embeddings,chunk_size_feed_forward,is_encoder_decoder,is_decoder,cross_attention_hidden_size,add_cross_attention,tie_encoder_decoder,max_length,min_length,do_sample,early_stopping,num_beams,num_beam_groups,diversity_penalty,temperature,top_k,top_p,typical_p,repetition_penalty,length_penalty,no_repeat_ngram_size,encoder_no_repeat_ngram_size,bad_words_ids,num_return_sequences,output_scores,return_dict_in_generate,forced_bos_token_id,forced_eos_token_id,remove_invalid_values,exponential_decay_length_penalty,suppress_tokens,begin_suppress_tokens,architectures,finetuning_task,id2label,label2id,tokenizer_class,prefix,bos_token_id,pad_token_id,eos_token_id,sep_token_id,decoder_start_token_id,task_specific_params,problem_type,_name_or_path,_attn_implementation_autoset,transformers_version,model_type,order_of_interleaved_layers,position_embedding_type,rotary_pct,use_embedding_sharing,use_gated_activation,use_parallel_block,use_parallel_embedding,Model Name,rms_norm_eps,pretraining_tp,mlp_bias,internal_version
0,256000,16384,4096,0.25,14336,32,32,8,silu,0.02,1e-05,True,50000.0,,False,0.0,4096.0,4.0,128,hybrid,True,False,False,False,float16,False,False,{},True,0,False,False,,False,False,20,0,False,False,1,1,0.0,1.0,50,1.0,1.0,1.0,1.0,0,0,,1,False,False,,,False,,,,['Cohere2ForCausalLM'],,"{0: 'LABEL_0', 1: 'LABEL_1'}","{'LABEL_0': 0, 'LABEL_1': 1}",,,5,0.0,255001,,,,,CohereForAI/c4ai-command-r7b-arabic-02-2025,True,4.49.0,cohere2,local_attn_first,rope_gptj,1.0,True,True,True,True,CohereForAI/c4ai-command-r7b-arabic-02-2025,,,,
1,64000,4096,4096,,11008,32,32,32,silu,0.006,,False,10000.0,,False,0.0,,,128,,True,False,False,False,float16,False,False,{},False,0,False,False,,False,False,20,0,False,False,1,1,0.0,1.0,50,1.0,1.0,1.0,1.0,0,0,,1,False,False,,,False,,,,['LlamaForCausalLM'],,"{0: 'LABEL_0', 1: 'LABEL_1'}","{'LABEL_0': 0, 'LABEL_1': 1}",,,1,,2,,,,,Navid-AI/Yehia-7B-preview,True,4.49.0,llama,,,,,,,,Navid-AI/Yehia-7B-preview,1e-05,1.0,False,7b-alpha-v1.27.2.25
2,64000,4096,4096,,11008,32,32,32,silu,0.006,,True,10000.0,,False,0.0,,,128,,True,False,False,False,bfloat16,False,False,{},False,0,False,False,,False,False,20,0,False,False,1,1,0.0,1.0,50,1.0,1.0,1.0,1.0,0,0,,1,False,False,,,False,,,,['LlamaForCausalLM'],,"{0: 'LABEL_0', 1: 'LABEL_1'}","{'LABEL_0': 0, 'LABEL_1': 1}",,,1,,2,,,,,ALLaM-AI/ALLaM-7B-Instruct-preview,True,4.49.0,llama,,,,,,,,ALLaM-AI/ALLaM-7B-Instruct-preview,1e-05,1.0,False,7b-alpha-v1.27.2.25
