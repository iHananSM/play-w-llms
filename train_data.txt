Llama models are large language models developed by Meta AI.
Continuing training a language model can help adapt it to specific domains.
Parameter efficient fine-tuning methods like LoRA reduce memory requirements.
